{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sx\n",
    "#@title Colab development environment settings\n",
    "if [ -n \"${COLAB_RELEASE_TAG}\" ]; then\n",
    "    git clone -b development https://github.com/MigeoDaSelva/DeepLVioDeSurVideos.git \\\n",
    "    && echo -e \"\\n\\nOkay!\\n\\n\" \\\n",
    "    || echo -e \"\\n\\nFAILED!\\n\\n\";\n",
    "    python3 -m pip install --upgrade pip;\n",
    "    python3 -m pip install -r /content/DeepLVioDeSurVideos/requirements.txt;\n",
    "    kill -9 pid \"${PPID}\";\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports libraries\n",
    "from statistics import mean\n",
    "from random import randint\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title System path manager\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "project_name = \"DeepLVioDeSurVideos\"\n",
    "\n",
    "working_directory = os.popen(\"echo $PWD\").read().rstrip()\n",
    "\n",
    "project_root_path = working_directory \\\n",
    "    if project_name in working_directory \\\n",
    "        else os.popen(\n",
    "            f\"readlink -f $(find -name {project_name})\"\n",
    "        ).read().rstrip()\n",
    "\n",
    "if str(project_root_path) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root_path))\n",
    "\n",
    "pprint(f\"Environment paths: {sys.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports project stuff\n",
    "from src.data_handler.strategies.video_creator import OpenCVVideoCreator, DecordVideoCreator\n",
    "from src.data_handler.strategies.class_names_finder import UniqueClassNamesFinder\n",
    "from src.data_handler.strategies.file_path_finder import (\n",
    "    RecursiveFilePathFinder,\n",
    "    FilePathFinderByLoad\n",
    "    )\n",
    "from src.data_handler.data_splitter import DataSplitter\n",
    "from configs import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Colab resource settings\n",
    "if settings.COLAB_ENV: \n",
    "    from google.colab import output\n",
    "    from google.colab import drive\n",
    "    output.enable_custom_widget_manager()\n",
    "    drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset attribute analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extensions = [\"avi\", \"mp4\"]\n",
    "\n",
    "file_path_finder = RecursiveFilePathFinder(file_extensions=file_extensions)\n",
    "class_finder = UniqueClassNamesFinder()\n",
    "# video_creator = DecordVideoCreator()\n",
    "video_creator = OpenCVVideoCreator()\n",
    "\n",
    "file_paths = file_path_finder.finds(Path(os.path.join(settings.DATASETS_PATH, f\"{settings.DATASET_NAME}/\")))\n",
    "total_of_videos = len(file_paths)\n",
    "video_extensions = {path.suffix for path in file_paths}\n",
    "video_classes = class_finder.finds(file_paths)\n",
    "video_per_class = {\n",
    "    label: len(\n",
    "        list(\n",
    "            filter(\n",
    "                lambda path: path.parent.name == label, file_paths\n",
    "            )\n",
    "        )\n",
    "    ) for label in video_classes\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Total of videos: {total_of_videos}\",\n",
    "    f\"Extentions: {', '.join(video_extensions)}\",\n",
    "    f\"Video classes: {', '.join(video_classes)}\",\n",
    "    f\"Total of classes: {len(video_classes)}\",\n",
    "    sep=\"\\n\"\n",
    "    )\n",
    "\n",
    "pprint(\n",
    "    {\"Total of videos per class\": video_per_class},\n",
    ")\n",
    "\n",
    "def gets_length(path: Path) -> int:\n",
    "    video_creator.opens(path)\n",
    "    return video_creator.gets_total_length()\n",
    "\n",
    "frames_per_video = list(\n",
    "    gets_length(path)\n",
    "    for path in file_paths\n",
    ")\n",
    "overall_frame_rate = round(mean(frames_per_video))\n",
    "higher_amount_of_frames = max(frames_per_video)\n",
    "lowest_amount_of_frames = min(frames_per_video)\n",
    "\n",
    "overall_frame_rate_per_class = {\n",
    "    label: round(\n",
    "        mean(\n",
    "            gets_length(path) for path in list(\n",
    "                filter(\n",
    "                    lambda path: path.parent.name == label, file_paths\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ) for label in video_classes\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Overall frame rate: {overall_frame_rate}\",\n",
    "    (\"Higher and lowest amount of frames: \"\n",
    "        f\"{higher_amount_of_frames}, \"\n",
    "        f\"{lowest_amount_of_frames}\"),\n",
    "    sep=\"\\n\"\n",
    ")\n",
    "pprint(\n",
    "    {\"Overall frame rate per class\": overall_frame_rate_per_class},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single random sample analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = randint(0, len(file_paths)-1)\n",
    "\n",
    "video_creator = DecordVideoCreator(required_length=60)\n",
    "# video_creator = OpenCVVideoCreator(required_length=60)\n",
    "\n",
    "video = video_creator.creates(file_paths[index])\n",
    "\n",
    "print(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Selects the top ten\n",
    "sorted_classes = dict(sorted(video_per_class.items(), key=lambda item: item[1], reverse=True))\n",
    "top_10_classes = list(sorted_classes.keys())[:10]\n",
    "\n",
    "file_paths = file_path_finder.finds(Path(os.path.join(settings.DATASETS_PATH, f\"{settings.DATASET_NAME}/\")))\n",
    "\n",
    "print(f\"Total of videos before selecting the top 10 classes with the largest sample: {len(file_paths)}\\n\")\n",
    "\n",
    "dataset_paths = []\n",
    "\n",
    "for label in top_10_classes: \n",
    "    dataset_paths.extend(list(\n",
    "        filter(\n",
    "            lambda path: path.match(f\"*/{label}/*\"), file_paths\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "file_paths = dataset_paths\n",
    "\n",
    "pprint({\"Top 10 classes\": top_10_classes})\n",
    "print(f\"\\nTotal of videos after selection: {len(dataset_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splitter = DataSplitter(file_paths, train_size=0.8, validation_size=0.375)\n",
    "\n",
    "data_splitter.splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = randint(0, data_splitter.n_iterations-1)\n",
    "fold = randint(0, data_splitter.k_folds-1)\n",
    "\n",
    "train_file_paths = FilePathFinderByLoad().finds(Path(f'{settings.CROSS_VALIDATION_FILE_PATH}/{iteration}_{fold}_train.pickle'))\n",
    "test_file_paths = FilePathFinderByLoad().finds(Path(f'{settings.CROSS_VALIDATION_FILE_PATH}/{iteration}_{fold}_test.pickle'))\n",
    "validation_file_paths = FilePathFinderByLoad().finds(Path(f'{settings.CROSS_VALIDATION_FILE_PATH}/{iteration}_{fold}_validation.pickle'))\n",
    "\n",
    "train_classes =  UniqueClassNamesFinder().finds(train_file_paths)\n",
    "test_classes =  UniqueClassNamesFinder().finds(test_file_paths)\n",
    "validation_classes =  UniqueClassNamesFinder().finds(validation_file_paths)\n",
    "\n",
    "\n",
    "video_per_class_train = {\n",
    "    label: len(\n",
    "        list(\n",
    "            filter(\n",
    "                lambda path: path.parent.name == label, train_file_paths\n",
    "            )\n",
    "        )\n",
    "    ) for label in train_classes\n",
    "}\n",
    "\n",
    "video_per_class_test = {\n",
    "    label: len(\n",
    "        list(\n",
    "            filter(\n",
    "                lambda path: path.parent.name == label, test_file_paths\n",
    "            )\n",
    "        )\n",
    "    ) for label in test_classes\n",
    "}\n",
    "\n",
    "video_per_class_validation = {\n",
    "    label: len(\n",
    "        list(\n",
    "            filter(\n",
    "                lambda path: path.parent.name == label, validation_file_paths\n",
    "            )\n",
    "        )\n",
    "    ) for label in validation_classes\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Random observation\\nIteration: {iteration}\\nFold: {fold}\\n\",\n",
    "    f\"Train size: {len(train_file_paths)}\",\n",
    "    f\"Test size: {len(test_file_paths)}\",\n",
    "    f\"Validation size: {len(validation_file_paths)}\\n\", \n",
    "    sep=\"\\n\"\n",
    ")\n",
    "\n",
    "pprint(\n",
    "    {\"Videos per class in train set\": video_per_class_train,\n",
    "    \"Videos per class in test set\": video_per_class_test,\n",
    "    \"Videos per class in validation set\": video_per_class_validation}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
